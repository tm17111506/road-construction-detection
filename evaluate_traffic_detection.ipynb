{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af028f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102 True\n"
     ]
    }
   ],
   "source": [
    "# check pytorch installation: \n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "assert torch.__version__.startswith(\"1.9\")   # please manually install torch 1.9 if Colab changes its default version\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import tqdm\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import detection_utils as utils\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e73c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the datasets\n",
    "def get_data(dataroot, file_name):\n",
    "    def ret_data():\n",
    "        output_path = os.path.join(dataroot, file_name)\n",
    "        print(output_path)\n",
    "        assert os.path.exists(output_path)\n",
    "        with open(output_path, 'r') as fd:\n",
    "            data = json.load(fd)\n",
    "        fd.close()\n",
    "        return data\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81643940",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/usr0/tma1/datasets/nuimages/detectron_data'\n",
    "train_file = 'v1.0-train_trafficcone_detectron.json'\n",
    "val_file = 'val_val_trafficcone_detectron.json'\n",
    "test_file = 'val_test_trafficcone_detectron.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96359ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {0: 'traffic_cones'}\n",
    "data_train = DatasetCatalog.register(\"nuimages_train_trafficone\", get_data(dataroot, train_file))\n",
    "MetadataCatalog.get(\"nuimages_train_trafficone\").thing_classes = category_dict\n",
    "data_val = DatasetCatalog.register(\"nuimages_val_trafficone\", get_data(dataroot, val_file))\n",
    "MetadataCatalog.get(\"nuimages_val_trafficone\").thing_classes = category_dict\n",
    "data_test = DatasetCatalog.register(\"nuimages_test_trafficone\", get_data(dataroot, test_file))\n",
    "MetadataCatalog.get(\"nuimages_test_trafficone\").thing_classes = category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f040908",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = '2021-10-26-01-38-57'\n",
    "gt_folder = '/usr0/tma1/datasets/nuimages/detectron_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "680fc70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr0/tma1/traffic_cone_detection/output/2021-10-26-01-38-57/evaluation_output/nuimages_test_trafficone\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "show_image=False\n",
    "output_dir='/usr0/tma1/datasets/nuimages/object_detection_annotations'\n",
    "predicted_dir='/usr0/tma1/traffic_cone_detection/output'\n",
    "visualize_dataset_name = 'nuimages_test_trafficone'\n",
    "split = 'test'\n",
    "\n",
    "scale=5.0\n",
    "predicted_output_folder = os.path.join(os.path.join(predicted_dir, date_time), 'predicted_output')\n",
    "if not os.path.exists(predicted_output_folder):\n",
    "    os.mkdir(predicted_output_folder)\n",
    "    \n",
    "prediction_name = date_time + '_' + visualize_dataset_name\n",
    "predicted_output_folder = os.path.join(predicted_output_folder, prediction_name)\n",
    "if not os.path.exists(predicted_output_folder):\n",
    "    os.mkdir(predicted_output_folder)\n",
    "    \n",
    "output_folder = os.path.join(os.path.join(predicted_dir, date_time), 'evaluation_output')\n",
    "output_split_folder = os.path.join(output_folder, visualize_dataset_name)\n",
    "if not os.path.exists(output_split_folder):\n",
    "    os.mkdir(output_split_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e753db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.OUTPUT_DIR = os.path.join('/usr0/tma1/traffic_cone_detection/output', date_time)\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0076499.pth\")\n",
    "# cfg.MODEL.DEVICE='cpu'\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6392e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instance(instance, category_dict):\n",
    "    class_name = category_dict[instance.get('pred_classes').data.cpu().numpy()[0]]\n",
    "    pred_boxes = instance.get('pred_boxes').tensor.data.cpu().numpy()[0]\n",
    "    score = instance.get('scores').data.cpu().numpy()[0]\n",
    "    return '{} {} {} {} {} {}'.format(class_name, score, pred_boxes[0], pred_boxes[1], pred_boxes[2], pred_boxes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d72951eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr0/tma1/datasets/nuimages/detectron_data/val_test_trafficcone_detectron.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2263/2263 [05:55<00:00,  6.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dicts = list(chain.from_iterable([DatasetCatalog.get(k) for k in [visualize_dataset_name]]))\n",
    "metadata = MetadataCatalog.get(visualize_dataset_name)\n",
    "i = 0;\n",
    "for dic in tqdm.tqdm(dicts):\n",
    "    im = utils.read_image(dic[\"file_name\"], \"RGB\")\n",
    "    outputs = predictor(im)\n",
    "    predictions = []\n",
    "    for i in range(len(outputs['instances'])):\n",
    "        predictions.append(format_instance(outputs['instances'][i], category_dict))\n",
    "    \n",
    "    img_name = dic[\"file_name\"].split('/')[-1]\n",
    "    txt_name = img_name.split('.')[0] + '.txt'\n",
    "    txt_name = os.path.join(output_split_folder, txt_name)\n",
    "    \n",
    "    # Write result to folder\n",
    "    with open(txt_name, 'w+') as fd:\n",
    "        fd.write('\\n'.join(predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94f80e",
   "metadata": {},
   "source": [
    "Create ground truth formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6464f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2263/2263 [00:00<00:00, 28436.94it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_eval = '/usr0/tma1/datasets/nuimages/detectron_data/evaluation_ground_truth'\n",
    "gt_eval_split = os.path.join(gt_eval, visualize_dataset_name)\n",
    "if not os.path.exists(gt_eval_split):\n",
    "    os.mkdir(gt_eval_split)\n",
    "\n",
    "with open(os.path.join(dataroot, test_file), 'r') as fd:\n",
    "    data = json.load(fd)\n",
    "    i = 0;\n",
    "    for d in tqdm.tqdm(data):\n",
    "        i += 1\n",
    "        img_name = d['file_name'].split('/')[-1]\n",
    "        txt_name = img_name.split('.')[0] + '.txt'\n",
    "        annotation = []\n",
    "        for anno in d['annotations']:\n",
    "            pred_boxes = anno['bbox']\n",
    "            class_name = category_dict[anno['category_id']]\n",
    "            rslt = '{} {} {} {} {}'.format(class_name, pred_boxes[0], pred_boxes[1], pred_boxes[2], pred_boxes[3])\n",
    "            annotation.append(rslt)\n",
    "        \n",
    "        out_file = os.path.join(gt_eval_split, txt_name)\n",
    "        with open(out_file, 'w+') as fd:\n",
    "            fd.write('\\n'.join(annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efa280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc64bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuimages import NuImages\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from itertools import groupby\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55f4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/usr0/tma1/datasets/nuimages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f043fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating category id files...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Creating category id files...')\n",
    "category_file = os.path.join(dataroot, 'category_id.json')\n",
    "if (not os.path.exists(category_file)):\n",
    "    fd = open(os.path.join(dataroot, 'v1.0-train/category.json'), 'r')\n",
    "    category = json.load(fd)\n",
    "    category_id = dict()\n",
    "    \n",
    "    for i, cat in enumerate(category):\n",
    "        category_id[cat['name']] = i\n",
    "    \n",
    "    fd2 = open(category_file, 'w+')\n",
    "    json.dump(category_id, fd2)\n",
    "    \n",
    "    fd.close()\n",
    "    fd2.close()\n",
    "else:\n",
    "    category_id_file = os.path.join(dataroot, 'category_id.json')\n",
    "    fd = open(category_id_file, 'r')\n",
    "    category_id = json.load(fd)\n",
    "    fd.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d120de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_file_name = 'construction_vehicle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564feccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vehicle.construction': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([18], {18: 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find category_ids that are of interest\n",
    "construction_names = ['vehicle.construction']\n",
    "construction_org_ids = [category_id[name] for name in construction_names]\n",
    "construction_new_ids = {category_id[name]: i for i, name in enumerate(construction_names)}\n",
    "print({name: i for i, name in enumerate(construction_names)})\n",
    "construction_org_ids, construction_new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2dd53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter detectron data for v1.0-train\n",
      "... done\n",
      "Filter detectron data for v1.0-val\n",
      "... done\n",
      "Filter detectron data for v1.0-test\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "# Splits the train, val, test data such that only categories of interest are retained\n",
    "splits = ['v1.0-train', 'v1.0-val', 'v1.0-test']\n",
    "for split in splits:\n",
    "    print(\"Filter detectron data for {}\".format(split))\n",
    "    path = os.path.join(os.path.join(dataroot, 'detectron_data'), split + '_detectron.json')\n",
    "    fd = open(path, 'r')\n",
    "    data = json.load(fd)\n",
    "    \n",
    "    filtered_data = []\n",
    "    for d in data:\n",
    "        filtered_anns = []\n",
    "        d_anns = d['annotations']\n",
    "            \n",
    "        for ann in d_anns:\n",
    "            if ann['category_id'] in construction_org_ids:\n",
    "                ann['category_id'] = construction_new_ids[ann['category_id']]\n",
    "                filtered_anns.append(ann)\n",
    "        \n",
    "        if (len(filtered_anns) > 0):\n",
    "            d['annotations'] = filtered_anns\n",
    "            filtered_data.append(d)\n",
    "    \n",
    "    path = os.path.join(os.path.join(dataroot, 'detectron_data'), split + '_{}_detectron.json'.format(category_file_name))\n",
    "    fd2 = open(path, 'w+')\n",
    "    json.dump(filtered_data, fd2)\n",
    "    \n",
    "    fd.close()\n",
    "    fd2.close()\n",
    "    print(\"... done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243e3efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr0/tma1/datasets/nuimages/detectron_data/v1.0-val_construction_vehicle_detectron.json\n",
      "1111\n"
     ]
    }
   ],
   "source": [
    "# Split validation data into validation and test\n",
    "path = os.path.join(os.path.join(dataroot, 'detectron_data'), 'v1.0-val_{}_detectron.json'.format(category_file_name))\n",
    "print(path)\n",
    "fd = open(path, 'r')\n",
    "data = json.load(fd)\n",
    "print(len(data))\n",
    "num_instances = len(data)\n",
    "indices = np.arange(num_instances)\n",
    "np.random.shuffle(indices)\n",
    "split_index = int(num_instances / 2)\n",
    "\n",
    "data_val = list(np.array(data)[indices[:split_index]])\n",
    "data_test = list(np.array(data)[indices[split_index:]])\n",
    "\n",
    "val_path = os.path.join(os.path.join(dataroot, 'detectron_data'), 'val_val_{}_detectron.json'.format(category_file_name))\n",
    "test_path = os.path.join(os.path.join(dataroot, 'detectron_data'), 'val_test_{}_detectron.json'.format(category_file_name))\n",
    "\n",
    "fd_val = open(val_path, 'w+')\n",
    "json.dump(data_val, fd_val)\n",
    "\n",
    "fd_test = open(test_path, 'w+')\n",
    "json.dump(data_test, fd_test)\n",
    "\n",
    "fd_val.close()\n",
    "fd_test.close()\n",
    "fd.close()\n",
    "\n",
    "#Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9bc49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch from list to dictionary format indexing by image_id as key\n",
    "val_path = os.path.join(os.path.join(dataroot, 'detectron_data'), 'val_val_{}_detectron.json'.format(category_file_name))\n",
    "fd = open(val_path, 'r')\n",
    "data = json.load(fd)\n",
    "fd.close()\n",
    "\n",
    "val_path_data = os.path.join(os.path.join(dataroot, 'detectron_data'), 'v1.0-val_val_{}_detectron.json'.format(category_file_name))\n",
    "val_data = dict()\n",
    "for d in data:\n",
    "    val_data[d['image_id']] = d\n",
    "\n",
    "fd = open(val_path_data, 'w+')\n",
    "json.dump(json.dumps(val_data), fd)\n",
    "\n",
    "test_path = os.path.join(os.path.join(dataroot, 'detectron_data'), 'val_test_{}_detectron.json'.format(category_file_name))\n",
    "fd = open(test_path, 'r')\n",
    "data = json.load(fd)\n",
    "fd.close()\n",
    "\n",
    "test_path_data = os.path.join(os.path.join(dataroot, 'detectron_data'), 'v1.0-val_test_{}_detectron.json'.format(category_file_name))\n",
    "test_data = dict()\n",
    "for d in data:\n",
    "    test_data[d['image_id']] = d\n",
    "\n",
    "fd = open(test_path_data, 'w+')\n",
    "json.dump(json.dumps(test_data), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f1133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
